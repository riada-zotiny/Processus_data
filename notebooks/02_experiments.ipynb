{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dec561b",
   "metadata": {},
   "source": [
    "# Notebook 2: Expériences sur les modèles\n",
    "\n",
    "**Auteurs:**  \n",
    "\n",
    "Akram Farihi, Sami Abloui, Amalya Mourih \n",
    "\n",
    "**Objectifs de notebook:**\n",
    "\n",
    "Dans ce notebook, nous réalisons l'entraînement sur les modèles choisis avec accomagnement de MLFlows et le reste. Nous avons le code preprocessing.py qui permettra de faire le prétraiment des données. et nous allons effectue nis exp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b231e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les lib importé \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bcd805",
   "metadata": {},
   "source": [
    "Preprocessing data avant de pouvoir l'entraineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e6373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=['Sleep_Quality'])\n",
    "y = df['Sleep_Quality']\n",
    "\n",
    "# appliquer une répartition stratifiée car nos données sont déséquilibrées\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ce72a",
   "metadata": {},
   "source": [
    "Nous allons ensuite construire un pipeline afin d’automatiser la normalisation des données, l’entraînement des modèles et la définition des bonnes grilles de paramètres. Nous avons choisi d’utiliser des modèles de classification plutôt que des modèles de régression, car notre objectif est de prédire une classe. Trois approches seront donc évaluées :\n",
    "\n",
    "- SVM, un classifieur performant et adapté aux jeux de données de taille moyenne.\n",
    "\n",
    "- RandomForest, un modèle simple, non paramétrique et efficace, qui classe les instances selon la proximité de leurs voisins.\n",
    "\n",
    "- MLP, un réseau de neurones adapté aux données tabulaires, contrairement aux CNN destinés aux images et aux RNN conçus pour les données séquentielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd888dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipelines = {\n",
    "    \"\": Pipeline([\n",
    "        (\"scaler\", MinMaxScaler),\n",
    "        (\"model\", RandomForestClassifier())\n",
    "    ]),\n",
    "    \"svm\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", SVC())\n",
    "    ]),\n",
    "    \"mlp\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", MLPClassifier(max_iter=300))\n",
    "    ])\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"randomforest\": {\n",
    "        \"model__n_estimators\": [100, 200, 300],      \n",
    "        \"model__max_depth\": [None, 5, 10, 20],       \n",
    "        \"model__min_samples_split\": [2, 5, 10],      \n",
    "        \"model__min_samples_leaf\": [1, 2, 4],       \n",
    "        \"model__bootstrap\": [True, False]            \n",
    "    },\n",
    "    \"svm\": {\n",
    "        \"model__C\": [0.1, 1, 10],\n",
    "        \"model__kernel\": [\"rbf\", \"linear\"]\n",
    "    },\n",
    "    \"mlp\": {\n",
    "        \"model__hidden_layer_sizes\": [(50,), (100,), (50,50)],\n",
    "        \"model__activation\": [\"relu\", \"tanh\"],\n",
    "        \"model__alpha\": [0.0001, 0.001]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b06844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_models = {}\n",
    "best_scores = {}\n",
    "\n",
    "for name in pipelines:\n",
    "    print(\"Recherche modèle :\", name)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipelines[name],\n",
    "        param_grid=param_grids[name],\n",
    "        cv=3,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[name] = grid.best_estimator_\n",
    "    best_scores[name] = grid.best_score_\n",
    "    \n",
    "    print(\"Meilleurs paramètres :\", grid.best_params_)\n",
    "    print(\"Score CV :\", grid.best_score_)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98046395",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name = max(best_scores, key=best_scores.get)\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "print(\"Meilleur modèle :\", best_model_name)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
